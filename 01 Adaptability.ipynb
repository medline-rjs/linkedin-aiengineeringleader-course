{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does good AI middleware like Semantic Kernel do for your **Adaptability**? It gives gives you a good toolbelt to take on any situation that comes your way.\n",
    "\n",
    "![](assets/toolbelt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 We warm up a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.1.0</span></li><li><span>SkiaSharp, 2.88.3</span></li><li><span>System.Linq.Async, 6.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\rnsmith\\.nuget\\packages\\skiasharp\\2.88.3\\interactive-extensions\\dotnet\\SkiaSharp.DotNet.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.1.0\"\n",
    "#r \"nuget: System.Linq.Async, 6.0.1\"\n",
    "#r \"nuget: SkiaSharp, 2.88.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Load settings\n",
    "#!import config/Settings.cs \n",
    "#!import config/SkiaUtils.cs \n",
    "\n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.Threading.Tasks;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "using SemanticKernel = Microsoft.SemanticKernel.Kernel;\n",
    "\n",
    "// Create a kernel with OpenAI chat completion\n",
    "SemanticKernel kernel = SemanticKernel.CreateBuilder()\n",
    "    .AddOpenAIChatCompletion(\n",
    "        modelId: model,\n",
    "        apiKey: apiKey)\n",
    "    .Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💬 How many ways can I prompt thee?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① We've got vanilla prompts easy-peasy for u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Microsoft.SemanticKernel.HttpOperationException: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\r\nStatus: 429 (Too Many Requests)\r\nErrorCode: insufficient_quota\r\n\r\nContent:\r\n{\n    \"error\": {\n        \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\n        \"type\": \"insufficient_quota\",\n        \"param\": null,\n        \"code\": \"insufficient_quota\"\n    }\n}\n\r\n\r\nHeaders:\r\nDate: Wed, 28 Feb 2024 22:14:36 GMT\r\nConnection: keep-alive\r\nVary: REDACTED\r\nX-Request-ID: REDACTED\r\nStrict-Transport-Security: REDACTED\r\nCF-Cache-Status: REDACTED\r\nSet-Cookie: REDACTED\r\nServer: cloudflare\r\nCF-RAY: REDACTED\r\nAlt-Svc: REDACTED\r\nContent-Type: application/json; charset=utf-8\r\nContent-Length: 337\r\n\r\n ---> Azure.RequestFailedException: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\r\nStatus: 429 (Too Many Requests)\r\nErrorCode: insufficient_quota\r\n\r\nContent:\r\n{\n    \"error\": {\n        \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\n        \"type\": \"insufficient_quota\",\n        \"param\": null,\n        \"code\": \"insufficient_quota\"\n    }\n}\n\r\n\r\nHeaders:\r\nDate: Wed, 28 Feb 2024 22:14:36 GMT\r\nConnection: keep-alive\r\nVary: REDACTED\r\nX-Request-ID: REDACTED\r\nStrict-Transport-Security: REDACTED\r\nCF-Cache-Status: REDACTED\r\nSet-Cookie: REDACTED\r\nServer: cloudflare\r\nCF-RAY: REDACTED\r\nAlt-Svc: REDACTED\r\nContent-Type: application/json; charset=utf-8\r\nContent-Length: 337\r\n\r\n   at Azure.Core.HttpPipelineExtensions.ProcessMessageAsync(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletionsAsync(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.RunRequestAsync[T](Func`1 request)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.RunRequestAsync[T](Func`1 request)\r\n   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.GetChatMessageContentsAsync(ChatHistory chat, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.ChatCompletion.ChatCompletionServiceExtensions.GetChatMessageContentAsync(IChatCompletionService chatCompletionService, String prompt, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Submission#8.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Microsoft.SemanticKernel.HttpOperationException: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\r\n",
      "Status: 429 (Too Many Requests)\r\n",
      "ErrorCode: insufficient_quota\r\n",
      "\r\n",
      "Content:\r\n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\n",
      "        \"type\": \"insufficient_quota\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"insufficient_quota\"\n",
      "    }\n",
      "}\n",
      "\r\n",
      "\r\n",
      "Headers:\r\n",
      "Date: Wed, 28 Feb 2024 22:14:36 GMT\r\n",
      "Connection: keep-alive\r\n",
      "Vary: REDACTED\r\n",
      "X-Request-ID: REDACTED\r\n",
      "Strict-Transport-Security: REDACTED\r\n",
      "CF-Cache-Status: REDACTED\r\n",
      "Set-Cookie: REDACTED\r\n",
      "Server: cloudflare\r\n",
      "CF-RAY: REDACTED\r\n",
      "Alt-Svc: REDACTED\r\n",
      "Content-Type: application/json; charset=utf-8\r\n",
      "Content-Length: 337\r\n",
      "\r\n",
      " ---> Azure.RequestFailedException: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\r\n",
      "Status: 429 (Too Many Requests)\r\n",
      "ErrorCode: insufficient_quota\r\n",
      "\r\n",
      "Content:\r\n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\n",
      "        \"type\": \"insufficient_quota\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"insufficient_quota\"\n",
      "    }\n",
      "}\n",
      "\r\n",
      "\r\n",
      "Headers:\r\n",
      "Date: Wed, 28 Feb 2024 22:14:36 GMT\r\n",
      "Connection: keep-alive\r\n",
      "Vary: REDACTED\r\n",
      "X-Request-ID: REDACTED\r\n",
      "Strict-Transport-Security: REDACTED\r\n",
      "CF-Cache-Status: REDACTED\r\n",
      "Set-Cookie: REDACTED\r\n",
      "Server: cloudflare\r\n",
      "CF-RAY: REDACTED\r\n",
      "Alt-Svc: REDACTED\r\n",
      "Content-Type: application/json; charset=utf-8\r\n",
      "Content-Length: 337\r\n",
      "\r\n",
      "   at Azure.Core.HttpPipelineExtensions.ProcessMessageAsync(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n",
      "   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletionsAsync(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.RunRequestAsync[T](Func`1 request)\r\n",
      "   --- End of inner exception stack trace ---\r\n",
      "   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.RunRequestAsync[T](Func`1 request)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.OpenAI.ClientCore.GetChatMessageContentsAsync(ChatHistory chat, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.ChatCompletion.ChatCompletionServiceExtensions.GetChatMessageContentAsync(IChatCompletionService chatCompletionService, String prompt, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Submission#8.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "// Example 1. Invoke the kernel with a prompt and display the result\n",
    "Console.WriteLine(await kernel.InvokePromptAsync(\"What is the favorite food of winnie the pooh\"));\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② Can I use templates? We're getting more {{ handlebars-y }} ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Example 2. Invoke the kernel with a templated prompt and display the result\n",
    "KernelArguments arguments = new() { { \"topic\", \"grand canyon\" }, { \"meal\", \"sushi\" } };\n",
    "Console.WriteLine(await kernel.InvokePromptAsync(\"What color is the {{$topic}} and how is {{$meal}} cooked?\", arguments));\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ③ Got streaming? Yes, we have that in stock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await foreach (var update in kernel.InvokePromptStreamingAsync(\"What color is the {{$topic}}? Provide a detailed explanation.\", arguments))\n",
    "{\n",
    "    Console.Write(update);\n",
    "}\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ④ I need to tune my hyperparameters ... abs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "arguments = new(new OpenAIPromptExecutionSettings { MaxTokens = 500, Temperature = 1.5 }) { { \"topic\", \"dogs\" } };\n",
    "Console.WriteLine(await kernel.InvokePromptAsync(\"Tell me a story about {{$topic}}\", arguments));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌅 \"I want images. Lots of them.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 🖼️ You can auto-paint them with Dall-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.TextToImage;\n",
    "using Microsoft.SemanticKernel.Embeddings;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "\n",
    "using Kernel = Microsoft.SemanticKernel.Kernel;\n",
    "\n",
    "#pragma warning disable SKEXP0001, SKEXP0002, SKEXP0011, SKEXP0012\n",
    "\n",
    "var builder = Kernel.CreateBuilder();\n",
    "\n",
    "if(useAzureOpenAI)\n",
    "{\n",
    "    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);\n",
    "    builder.AddAzureOpenAITextToImage(\"dall-e-3\",azureEndpoint, apiKey);\n",
    "}\n",
    "else\n",
    "{\n",
    "    builder.AddOpenAIChatCompletion(model, apiKey, orgId);\n",
    "    builder.AddOpenAITextToImage(apiKey, orgId);\n",
    "}\n",
    "   \n",
    "var kernel = builder.Build();\n",
    "\n",
    "// Get AI service instance used to generate images\n",
    "var dallE = kernel.GetRequiredService<ITextToImageService>();\n",
    "\n",
    "\n",
    "#pragma warning disable SKEXP0002\n",
    "\n",
    "var prompt = @\"\n",
    "Think about an artificial object correlated to number {{$input}}.\n",
    "Describe the image with one detailed sentence. The description cannot contain numbers.\";\n",
    "\n",
    "var executionSettings = new OpenAIPromptExecutionSettings \n",
    "{\n",
    "    MaxTokens = 256,\n",
    "    Temperature = 1\n",
    "};\n",
    "\n",
    "// Create a semantic function that generate a random image description.\n",
    "var genImgDescription = kernel.CreateFunctionFromPrompt(prompt, executionSettings);\n",
    "\n",
    "var random = new Random().Next(0, 200);\n",
    "var imageDescriptionResult = await kernel.InvokeAsync(genImgDescription, new() { [\"input\"] = random });\n",
    "var imageDescription = imageDescriptionResult.ToString();\n",
    "\n",
    "// Use DALL-E 2 to generate an image. OpenAI in this case returns a URL (though you can ask to return a base64 image)\n",
    "var imageUrl = await dallE.GenerateImageAsync(imageDescription.Trim(), 512, 512);\n",
    "\n",
    "await SkiaUtils.ShowImage(imageUrl, 512, 512);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② 🦄 Or, you can read them with multimodal magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "const string ImageUri = \"https://i0.wp.com/maeda.pm/wp-content/uploads/2017/09/photo_dark_big.png\";\n",
    "\n",
    "await SkiaUtils.ShowImage(ImageUri, 512, 512);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ Note that you may not have access to `gpt-4-vision-preview` on OpenAI unless you have a paid subscription, and/or there's a waiting list to get access to it. Plus the name of the model is likely going to change. All model names for OAI are over [here](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.Threading.Tasks;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using SemanticKernel = Microsoft.SemanticKernel.Kernel;\n",
    "\n",
    "var kernel = SemanticKernel.CreateBuilder()\n",
    "    .AddOpenAIChatCompletion(\"gpt-4-vision-preview\", apiKey)\n",
    "    .Build();\n",
    "\n",
    "var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "var chatHistory = new ChatHistory(\"You are a friendly assistant.\");\n",
    "\n",
    "chatHistory.AddUserMessage(new ChatMessageContentItemCollection\n",
    "{\n",
    "    new TextContent(\"What’s in this image?\"),\n",
    "    new ImageContent(new Uri(imageUrl))\n",
    "    //new ImageContent(new Uri(ImageUri))\n",
    "});\n",
    "\n",
    "var reply = await chatCompletionService.GetChatMessageContentAsync(chatHistory);\n",
    "\n",
    "Console.WriteLine(reply.Content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧲 And then there's the 🫲 left hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// TO BE CONTINUED ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
